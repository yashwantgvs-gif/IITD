import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

def linear_regression(x_train, y_train):
    # Add a column of ones to the feature matrix for the bias term
    ones = np.ones((x_train.shape[0], 1))
    x_train = np.concatenate((ones, x_train), axis=1)

    # Calculate the coefficients using the closed-form solution
    x_transpose = np.transpose(x_train)
    x_transpose_dot_x = np.dot(x_transpose, x_train)
    x_transpose_dot_y = np.dot(x_transpose, y_train)
    coefficients = np.dot(np.linalg.inv(x_transpose_dot_x), x_transpose_dot_y)

    # Predict the outputs for the training data
    y_train_pred = np.dot(x_train, coefficients)

    return coefficients, y_train_pred

# Load the data from a CSV file
data = pd.read_csv(r"C:\Users\ASUS\Downloads\IITD-1\Medical Price Dataset (2).csv")

# Preprocessing steps
# Convert non-numeric columns to numeric
data['sex'] = data['sex'].map({'male': 0, 'female': 1})
data['smoker'] = data['smoker'].map({'no': 0, 'yes': 1})
data['region'] = data['region'].map({'southwest': 0, 'southeast': 1, 'northwest': 2, 'northeast': 3})

# Extract the features and target variable from the data
x_train = data.drop("charges", axis=1).to_numpy()
y_train = data["charges"].to_numpy()

# Perform linear regression
coefficients, y_train_pred = linear_regression(x_train, y_train)

# Print the coefficients
print("Coefficients:")
print(coefficients)

# Visualization using Matplotlib
# Plot the predicted outputs against the actual outputs
plt.scatter(y_train, y_train_pred)
plt.xlabel("Actual charges")
plt.ylabel("Predicted charges")
plt.title("Linear Regression - Actual vs Predicted charges")
plt.show()
